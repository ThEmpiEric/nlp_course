{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63d836a9-9e33-451e-aaef-537f47afd9b4",
   "metadata": {},
   "source": [
    "# Tarea 2. Minería de Texto Básica\n",
    "\n",
    "Procesamiento de Lenguaje Natural\n",
    "\n",
    "Eric Lemus Avalos \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea3b9b2-4482-40fd-9924-2b8a4f483ff7",
   "metadata": {},
   "source": [
    "Cargamos los datos y funciones de la práctica 2, creamos un tokenizador con TweetTokenizer. Creamos un diccionario de frecuencias y un diccionario character-index. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c5444747-c59c-4d77-8aaa-29a1522b6ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk \n",
    "import numpy as np  \n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from practica2 import get_text_from_file, order_dic_frec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b1201222-6205-4020-8acf-79f2f109bdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_train , target_train = get_text_from_file(\"./data_mex/mex20_train.txt\", \"./data_mex/mex20_train_labels.txt\")\n",
    "text_val, target_val = get_text_from_file(\"./data_mex/mex20_val (1).txt\", \"./data_mex/mex20_val_labels (1).txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6847a9bf-a582-413a-abdc-c3d713f8a257",
   "metadata": {},
   "outputs": [],
   "source": [
    "tk = TweetTokenizer()\n",
    "\n",
    "corpus = []\n",
    "for txt in text_train:\n",
    "    corpus += tk.tokenize(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "2e5e461b-69c0-4f97-8989-5e1f246887b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fdist = nltk.FreqDist(corpus)\n",
    "V = order_dic_frec(fdist)\n",
    "V = V[:5000]\n",
    "\n",
    "dict_index = dict()\n",
    "count = 0\n",
    "for weight, word in V:\n",
    "    dict_index[word] = count\n",
    "    count += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2aed2c-d81e-497f-b535-ebf1334bfa61",
   "metadata": {},
   "source": [
    "## Bolsas de palabras, Bigramas y Emociones\n",
    "\n",
    "1. Evalué BoW con pesado binario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "00dc0bed-4261-45a1-8bb5-0a3f55da55d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BoW(text, vocabulario, dict_index): \n",
    "    BOW = np.zeros((len(text),len(vocabulario)),dtype = int)\n",
    "     \n",
    "    cont_doc = 0 \n",
    "\n",
    "    for doc in text: \n",
    "        fdist_doc = nltk.FreqDist(tk.tokenize(doc))\n",
    "\n",
    "        #llenar la bolsa \n",
    "        for word in fdist_doc:\n",
    "            if word in dict_index: \n",
    "                BOW[cont_doc,dict_index[word]] = 1 #frecuencia 1 para cuando el i-termino esta en el j-doc\n",
    "        cont_doc += 1  \n",
    "    \n",
    "    return BOW "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0d0c9e3e-1572-4bf6-99dd-b5d01d31ce6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "BoW_bin_train = BoW(text_train,V,dict_index)\n",
    "BoW_bin_val   = BoW(text_val,V,dict_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "771eafd9-fdde-4664-a562-d5b4098673f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[358  60]\n",
      " [ 55 114]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8668    0.8565    0.8616       418\n",
      "           1     0.6552    0.6746    0.6647       169\n",
      "\n",
      "    accuracy                         0.8041       587\n",
      "   macro avg     0.7610    0.7655    0.7632       587\n",
      "weighted avg     0.8059    0.8041    0.8049       587\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, precision_recall_fscore_support, roc_auc_score\n",
    "\n",
    "parametros = {'C': [0.5, .12, .25, .5, 1, 2, 4]}\n",
    "\n",
    "clasificador = svm.LinearSVC(class_weight = 'balanced')  \n",
    "grid =  GridSearchCV(estimator = clasificador, param_grid = parametros, n_jobs = 8, scoring = \"f1_macro\",cv = 5)\n",
    "grid.fit(BoW_bin_train, target_train)\n",
    "y_pred = grid.predict(BoW_bin_val)\n",
    "\n",
    "p, r, f, _= precision_recall_fscore_support(target_val, y_pred, average='macro', pos_label=1)\n",
    "\n",
    "print(confusion_matrix(target_val,y_pred))\n",
    "print(metrics.classification_report(target_val,y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce12ed5-94c6-4088-9127-5eed829e7110",
   "metadata": {},
   "source": [
    "2. Evalué BoW con pesado frecuencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a71cf668-7341-4cc4-8cbe-63b197b2f17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BoW_frec(text, vocabulario, dict_index): \n",
    "    BOW = np.zeros((len(text),len(vocabulario)),dtype = int)\n",
    "     \n",
    "    cont_doc = 0 \n",
    "\n",
    "    for doc in text: \n",
    "        fdist_doc = nltk.FreqDist(tk.tokenize(doc))\n",
    "\n",
    "        #llenar la bolsa \n",
    "        for word in fdist_doc:\n",
    "            if word in dict_index: \n",
    "                BOW[cont_doc,dict_index[word]] = fdist_doc[word]\n",
    "        cont_doc += 1  \n",
    "    \n",
    "    return BOW "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f40c6c77-b003-4942-baf2-8d0af88c050f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[356  62]\n",
      " [ 54 115]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8683    0.8517    0.8599       418\n",
      "           1     0.6497    0.6805    0.6647       169\n",
      "\n",
      "    accuracy                         0.8024       587\n",
      "   macro avg     0.7590    0.7661    0.7623       587\n",
      "weighted avg     0.8054    0.8024    0.8037       587\n",
      "\n"
     ]
    }
   ],
   "source": [
    "BoW_frec_train = BoW_frec(text_train,V,dict_index)\n",
    "BoW_frec_val   = BoW_frec(text_val,V,dict_index)\n",
    "\n",
    "grid.fit(BoW_frec_train, target_train)\n",
    "y_pred = grid.predict(BoW_frec_val)\n",
    "\n",
    "p, r, f, _= precision_recall_fscore_support(target_val, y_pred, average='macro', pos_label=1)\n",
    "\n",
    "print(confusion_matrix(target_val,y_pred))\n",
    "print(metrics.classification_report(target_val,y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab15ed26-625c-464a-9b86-0d13a9064776",
   "metadata": {},
   "source": [
    "3. Evalué BoW con pesado tfidf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c36b380d-9743-4a87-a559-e3f93daad1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def BoW_tfidf(text, vocabulario, dict_index):\n",
    "    BOW = np.zeros((len(text), len(vocabulario)), dtype=float)\n",
    "    \n",
    "    df = defaultdict(int)  # df[word] = num de doc donde aparece la palabra\n",
    "    for doc in text:\n",
    "        unique_words = set(tk.tokenize(doc))  \n",
    "        for word in unique_words:\n",
    "            if word in dict_index:\n",
    "                df[word] += 1  \n",
    "    \n",
    "    cont_doc = 0\n",
    "    T = len(text)  # total doc\n",
    "    \n",
    "    for doc in text:\n",
    "        fdist_doc = nltk.FreqDist(tk.tokenize(doc))  \n",
    "        \n",
    "        for word in fdist_doc:\n",
    "            if word in dict_index:\n",
    "                tf = fdist_doc[word]\n",
    "                idf = np.log(T / df[word])\n",
    "                BOW[cont_doc, dict_index[word]] = tf * idf\n",
    "        cont_doc += 1\n",
    "    \n",
    "    return BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "966813fb-d12a-44e2-951e-7146eb31b492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[351  67]\n",
      " [ 78  91]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8182    0.8397    0.8288       418\n",
      "           1     0.5759    0.5385    0.5566       169\n",
      "\n",
      "    accuracy                         0.7530       587\n",
      "   macro avg     0.6971    0.6891    0.6927       587\n",
      "weighted avg     0.7484    0.7530    0.7504       587\n",
      "\n"
     ]
    }
   ],
   "source": [
    "BoW_TFidf_train = BoW_tfidf(text_train,V,dict_index)\n",
    "BoW_TFidf_val   = BoW_tfidf(text_val,V,dict_index)\n",
    "\n",
    "grid.fit(BoW_TFidf_train, target_train)\n",
    "y_pred = grid.predict(BoW_TFidf_val)\n",
    "\n",
    "p, r, f, _= precision_recall_fscore_support(target_val, y_pred, average='macro', pos_label=1)\n",
    "\n",
    "print(confusion_matrix(target_val,y_pred))\n",
    "print(metrics.classification_report(target_val,y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9035b549-261c-4a40-b411-cafbd2b10d22",
   "metadata": {},
   "source": [
    "4. Evalué BoW con pesado binario normalizado l2 (no use sklearn)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "af37a4c3-b6a6-4c48-a33b-a1a4c2309dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norma_l2(bow):\n",
    "    n,m = bow.shape \n",
    "    B_norm = np.zeros((n,m))\n",
    "    \n",
    "    for i in range(n):\n",
    "        norm = np.linalg.norm(bow[i, :])\n",
    "        if norm !=0:\n",
    "            B_norm[i, :] = bow[i, :]/norm\n",
    "    return B_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "236c39d7-0604-4249-8a3e-0ea674dd110c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[356  62]\n",
      " [ 47 122]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8834    0.8517    0.8672       418\n",
      "           1     0.6630    0.7219    0.6912       169\n",
      "\n",
      "    accuracy                         0.8143       587\n",
      "   macro avg     0.7732    0.7868    0.7792       587\n",
      "weighted avg     0.8199    0.8143    0.8166       587\n",
      "\n"
     ]
    }
   ],
   "source": [
    "BoW_l2_train = norma_l2(BoW_bin_train)\n",
    "BoW_l2_val   = norma_l2(BoW_bin_val)\n",
    "\n",
    "grid.fit(BoW_l2_train, target_train)\n",
    "y_pred = grid.predict(BoW_l2_val)\n",
    "\n",
    "p, r, f, _= precision_recall_fscore_support(target_val, y_pred, average='macro', pos_label=1)\n",
    "\n",
    "print(confusion_matrix(target_val,y_pred))\n",
    "print(metrics.classification_report(target_val,y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e638fb2d-f8ec-48b9-b8f0-7217647cd13e",
   "metadata": {},
   "source": [
    "5. Evalué BoW con pesado frecuencia normalizado l2 (no use sklearn)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "574eeea9-04c0-4336-8f85-a32bb773b2b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[358  60]\n",
      " [ 38 131]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9040    0.8565    0.8796       418\n",
      "           1     0.6859    0.7751    0.7278       169\n",
      "\n",
      "    accuracy                         0.8330       587\n",
      "   macro avg     0.7950    0.8158    0.8037       587\n",
      "weighted avg     0.8412    0.8330    0.8359       587\n",
      "\n"
     ]
    }
   ],
   "source": [
    "BoW_frecl2_train = norma_l2(BoW_frec_train)\n",
    "BoW_frecl2_val   = norma_l2(BoW_frec_val)\n",
    "\n",
    "grid.fit(BoW_frecl2_train, target_train)\n",
    "y_pred = grid.predict(BoW_frecl2_val)\n",
    "\n",
    "p, r, f, _= precision_recall_fscore_support(target_val, y_pred, average='macro', pos_label=1)\n",
    "\n",
    "print(confusion_matrix(target_val,y_pred))\n",
    "print(metrics.classification_report(target_val,y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48322860-a3ba-4e7e-9ee9-9df2e46dfbee",
   "metadata": {},
   "source": [
    "6. Evalué BoW con pesado tfidf normalizado l2 (no use sklearn)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b4578090-c7a7-40c7-98d5-812afe010c94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[352  66]\n",
      " [ 39 130]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9003    0.8421    0.8702       418\n",
      "           1     0.6633    0.7692    0.7123       169\n",
      "\n",
      "    accuracy                         0.8211       587\n",
      "   macro avg     0.7818    0.8057    0.7913       587\n",
      "weighted avg     0.8320    0.8211    0.8248       587\n",
      "\n"
     ]
    }
   ],
   "source": [
    "BoW_TFidf_train = norma_l2(BoW_TFidf_train)\n",
    "BoW_TFidf_val   = norma_l2(BoW_TFidf_val)\n",
    "\n",
    "grid.fit(BoW_TFidf_train, target_train)\n",
    "y_pred = grid.predict(BoW_TFidf_val)\n",
    "\n",
    "p, r, f, _= precision_recall_fscore_support(target_val, y_pred, average='macro', pos_label=1)\n",
    "\n",
    "print(confusion_matrix(target_val,y_pred))\n",
    "print(metrics.classification_report(target_val,y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db28ec12-8e93-4925-a31a-052edbc4f3c8",
   "metadata": {},
   "source": [
    "7. Ponga una tabla comparativa a modo de resumen con las seis entradas anteriores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007741ea-2cdc-43a3-9911-599ce9992f46",
   "metadata": {},
   "source": [
    "\n",
    "| Método                           | Accuracy | Macro F1 | F1-score(0) | F1-score(1) |\n",
    "|----------------------------------|----------|----------|------------|------------|\n",
    "| **BoW Binario**                  | 0.8041   | 0.7632   | 0.8616     | 0.6647     |\n",
    "| **BoW Frecuencia**                | 0.8024   | 0.7623   | 0.8599     | 0.6647     |\n",
    "| **BoW TF-IDF**                    | 0.7530   | 0.6927   | 0.8288     | 0.5566     |\n",
    "| **BoW Binario (L2 Norm.)**        | 0.8143   | 0.7792   | 0.8672     | 0.6912     |\n",
    "| **BoW Frecuencia (L2 Norm.)**     | 0.8330   | 0.8037   | 0.8796     | 0.7278     |\n",
    "| **BoW TF-IDF (L2 Norm.)**         | 0.8211   | 0.7913   | 0.8702     | 0.7123     |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250f7192-e174-4640-b43d-f0d2d89a6ee1",
   "metadata": {},
   "source": [
    "8. De las configuraciones anteriores elija la mejor y evalúela con más y menos términos\n",
    "(e.g., 1000 y 7000). Ponga una tabla dónde compare tres configuraciones distintas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "51d9bd7f-7710-4fff-9134-5268551071c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[346  72]\n",
      " [ 39 130]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8987    0.8278    0.8618       418\n",
      "           1     0.6436    0.7692    0.7008       169\n",
      "\n",
      "    accuracy                         0.8109       587\n",
      "   macro avg     0.7711    0.7985    0.7813       587\n",
      "weighted avg     0.8252    0.8109    0.8154       587\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Con 1000 terminos\n",
    "V = order_dic_frec(fdist)\n",
    "V_small = V[:1000]\n",
    "\n",
    "dict_index = dict()\n",
    "count = 0\n",
    "for weight, word in V_small:\n",
    "    dict_index[word] = count\n",
    "    count += 1\n",
    "\n",
    "# Elegimos BoW con pesado frecuencia norma l2\n",
    "BoW_frec_train = BoW_frec(text_train,V_small,dict_index)\n",
    "BoW_frec_val   = BoW_frec(text_val,V_small,dict_index)\n",
    "BoW_frecl2_train = norma_l2(BoW_frec_train)\n",
    "BoW_frecl2_val   = norma_l2(BoW_frec_val)\n",
    "\n",
    "grid.fit(BoW_frecl2_train, target_train)\n",
    "y_pred = grid.predict(BoW_frecl2_val)\n",
    "\n",
    "p, r, f, _= precision_recall_fscore_support(target_val, y_pred, average='macro', pos_label=1)\n",
    "\n",
    "print(confusion_matrix(target_val,y_pred))\n",
    "print(metrics.classification_report(target_val,y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4812d426-b412-4105-8673-0261b14355d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[359  59]\n",
      " [ 39 130]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9020    0.8589    0.8799       418\n",
      "           1     0.6878    0.7692    0.7263       169\n",
      "\n",
      "    accuracy                         0.8330       587\n",
      "   macro avg     0.7949    0.8140    0.8031       587\n",
      "weighted avg     0.8403    0.8330    0.8357       587\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Con 7000 terminos\n",
    "V = order_dic_frec(fdist)\n",
    "V_big = V[:7000]\n",
    "\n",
    "dict_index = dict()\n",
    "count = 0\n",
    "for weight, word in V_big:\n",
    "    dict_index[word] = count\n",
    "    count += 1\n",
    "\n",
    "# Elegimos BoW con pesado frecuencia norma l2\n",
    "BoW_frec_train = BoW_frec(text_train,V_big,dict_index)\n",
    "BoW_frec_val   = BoW_frec(text_val,V_big,dict_index)\n",
    "BoW_frecl2_train = norma_l2(BoW_frec_train)\n",
    "BoW_frecl2_val   = norma_l2(BoW_frec_val)\n",
    "\n",
    "grid.fit(BoW_frecl2_train, target_train)\n",
    "y_pred = grid.predict(BoW_frecl2_val)\n",
    "\n",
    "p, r, f, _= precision_recall_fscore_support(target_val, y_pred, average='macro', pos_label=1)\n",
    "\n",
    "print(confusion_matrix(target_val,y_pred))\n",
    "print(metrics.classification_report(target_val,y_pred, digits=4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3364dc-0788-4315-978c-919fc2903ebf",
   "metadata": {},
   "source": [
    "**Comparación BoW pesado de frecuencia (normalizado  l2) con diferentes tamaños de vocabulario**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "| Vocabulario | Accuracy | Macro F1 | F1-score(0) | F1-score(1) |\n",
    "|------------|----------|----------|------------|------------|\n",
    "| **1000**   | 0.8109   | 0.7813   | 0.8618     | 0.7008     |\n",
    "| **5000**   | 0.8330   | 0.8037   | 0.8796     | 0.7278     |\n",
    "| **7000**   | 0.8330   | 0.8031   | 0.8799     | 0.7263     |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe2acde-c3f9-4609-b92a-2eff0341c7e6",
   "metadata": {},
   "source": [
    "9. Utilice el recurso léxico del Consejo Nacional de Investigación de Canadá llamado\n",
    "\"EmoLex\" (https://www.saifmohammad.com/WebPages/NRC-Emotion-Lexicon.htm) para\n",
    "construir una \"Bolsa de Emociones\" de los Tweets de agresividad (Debe usar EmoLex en\n",
    "Español). Para esto, una estrategia sencilla sería enmascarar (sustituir) cada palabra con\n",
    "su emoción, y después construir la Bolsa de Emociones (BoE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c0093057-3bae-439f-81aa-a93c154f9944",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cargamos data\n",
    "path = r\"C:\\Users\\ericl\\Downloads\\NRC-Emotion-Lexicon\\NRC-Emotion-Lexicon\\OneFilePerLanguage\\Spanish-NRC-EmoLex.txt\"\n",
    "\n",
    "EmoLex = dict() #{palabra,puntaje emociones}\n",
    "\n",
    "with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "    next(f)\n",
    "    for line in f:\n",
    "        cols = line.strip().split(\"\\t\")  # Dividir por tabulación y limpiar espacios\n",
    "        spanish_word = cols[-1]  \n",
    "        emotions = list(map(int, cols[1:11]))\n",
    "        EmoLex[spanish_word] = emotions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e7392c0b-7b2a-4bd8-9703-289773698fd0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# EmoLex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7f5309b6-58af-4065-9106-c0025acb9716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(EmoLex.items())[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e6b1a14a-692c-4405-a744-9a1de40b764e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_emotions = {0:\"enojo\",1:\"anticipación\",2:\"disgusto\",3:\"miedo\",4:\"alegría\",\n",
    "                 5:\"negativo\",6:\"positivo\",7:\"tristeza\",8:\"sorpresa\",9:\"confianza\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "67fcaae1-4a9e-4014-8d7c-6b05b128d270",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from nltk.text import Text\n",
    "from unidecode import unidecode\n",
    "import nltk\n",
    "\n",
    "nlp = spacy.load('es_core_news_sm')\n",
    "\n",
    "def mask(text_train, dict_emotions, lexico):\n",
    "    emot_mask = []  \n",
    "    \n",
    "    for txt in text_train:\n",
    "        doc = nlp(unidecode(txt.lower()))\n",
    "        tokens = [token.lemma_ for token in doc]\n",
    "        \n",
    "        emotions = []\n",
    "        for word in tokens:\n",
    "            if word in lexico:\n",
    "                emotion_indx = [i for i, value in enumerate(lexico[word]) if value == 1]\n",
    "                word_emotions = [dict_emotions[i] for i in emotion_indx]\n",
    "                emotions.extend(word_emotions)\n",
    "            else:\n",
    "                emotions.append(word)\n",
    "                \n",
    "        emot_mask.append(Text(emotions))  \n",
    "        \n",
    "    return emot_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "39a89080-8a74-4346-b911-8bf872b2152d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_emotion_for_word(word, lexico, dict_emotions):\n",
    "    try:\n",
    "        emotions = lexico[word]\n",
    "        emotion_indices = [i for i, value in enumerate(emotions) if value == 1]\n",
    "        \n",
    "        if emotion_indices:\n",
    "            return [dict_emotions[i] for i in emotion_indices]\n",
    "        else:\n",
    "            return [\"sin emoción\"]  \n",
    "    except KeyError:\n",
    "        return [\"palabra no encontrada\"]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "470da1d7-cd05-4770-9063-b5ebace3c047",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    " # text_train[:10]\n",
    "reversed_dict = {emotion: emotion_id for emotion_id, emotion in dict_emotions.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3478b224-2165-46d9-b8e3-037ac488bf59",
   "metadata": {},
   "outputs": [],
   "source": [
    "emot_mask_train = mask(text_train,dict_emotions,EmoLex)\n",
    "emot_mask_val = mask(text_val,dict_emotions,EmoLex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6737cc35-a095-455c-b6fb-ec3dcb15c80e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# emot_mask_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4aa821f1-b2a1-4d70-8d1e-89af5887d7e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['disgusto', 'negativo']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_emotion_for_word('obeso',EmoLex,dict_emotions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "53778add-736b-40f6-9996-a35258019c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BoE(text, dict_emotions): \n",
    "    BOE = np.zeros((len(text),len(dict_emotions)),dtype = int)\n",
    "     \n",
    "    cont_doc = 0 \n",
    "    for doc in text: \n",
    "        fdist_doc = nltk.FreqDist(doc)\n",
    "        for word in fdist_doc:\n",
    "            if word in dict_emotions: \n",
    "                BOE[cont_doc,dict_emotions[word]] = 1\n",
    "        cont_doc += 1  \n",
    "    \n",
    "    return BOE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b4ec6b30-4e01-4d82-8a10-4c2c29ab8177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizamos ya que previamnete obtuvimos mejores resultandos\n",
    "BOE_bin_train = norma_l2(BoE(emot_mask_train,reversed_dict))\n",
    "BOE_bin_val = norma_l2(BoE(emot_mask_val,reversed_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6cd5d62-5b33-4984-aaff-2aa8cc48cd2d",
   "metadata": {},
   "source": [
    "10. Usa tú BoE de alguna forma y clasifica con SVM. Ponga una tabla comparativa a modo\n",
    "de resumen con tres pesados (bin, tf, tfidf), normalize cada uno si lo cree conveniente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2c226ce4-efa7-4de2-a38c-a50b25cd95f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[297 121]\n",
      " [ 95  74]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7577    0.7105    0.7333       418\n",
      "           1     0.3795    0.4379    0.4066       169\n",
      "\n",
      "    accuracy                         0.6320       587\n",
      "   macro avg     0.5686    0.5742    0.5700       587\n",
      "weighted avg     0.6488    0.6320    0.6393       587\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grid.fit(BOE_bin_train, target_train)\n",
    "y_pred = grid.predict(BOE_bin_val)\n",
    "\n",
    "p, r, f, _= precision_recall_fscore_support(target_val, y_pred, average='macro', pos_label=1)\n",
    "\n",
    "print(confusion_matrix(target_val,y_pred))\n",
    "print(metrics.classification_report(target_val,y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "261273bf-eacc-4b67-8b2e-4c176c6339ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BoE_frec(text, dict_emotions): \n",
    "    BOE = np.zeros((len(text),len(dict_emotions)),dtype = int)\n",
    "     \n",
    "    cont_doc = 0 \n",
    "    for doc in text: \n",
    "        fdist_doc = nltk.FreqDist(doc)\n",
    "        for word in fdist_doc:\n",
    "            if word in dict_emotions: \n",
    "                BOE[cont_doc,dict_emotions[word]] = fdist_doc[word]\n",
    "        cont_doc += 1  \n",
    "    \n",
    "    return BOE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "451f34b3-8c39-405c-9861-24ba43f847c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[294 124]\n",
      " [ 97  72]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7519    0.7033    0.7268       418\n",
      "           1     0.3673    0.4260    0.3945       169\n",
      "\n",
      "    accuracy                         0.6235       587\n",
      "   macro avg     0.5596    0.5647    0.5607       587\n",
      "weighted avg     0.6412    0.6235    0.6312       587\n",
      "\n"
     ]
    }
   ],
   "source": [
    "BOE_frec_train = norma_l2(BoE_frec(emot_mask_train,reversed_dict))\n",
    "BOE_frec_val = norma_l2(BoE_frec(emot_mask_val,reversed_dict))\n",
    "\n",
    "grid.fit(BOE_frec_train, target_train)\n",
    "y_pred = grid.predict(BOE_frec_val)\n",
    "\n",
    "p, r, f, _= precision_recall_fscore_support(target_val, y_pred, average='macro', pos_label=1)\n",
    "\n",
    "print(confusion_matrix(target_val,y_pred))\n",
    "print(metrics.classification_report(target_val,y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "02d07946-f3c1-43d6-8e93-4ff0e2f87228",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BoE_tfidf(text, dict_emotions):\n",
    "    BOE = np.zeros((len(text), len(dict_emotions)), dtype=float)\n",
    "         \n",
    "    df = {word: sum(1 for doc in text if word in doc) for word in dict_emotions}\n",
    "            \n",
    "    cont_doc = 0\n",
    "    T = len(text)  \n",
    "    for doc in text:\n",
    "        fdist_doc = nltk.FreqDist(doc)  \n",
    "        \n",
    "        for word in fdist_doc:\n",
    "            if word in dict_emotions:\n",
    "                tf = fdist_doc[word]\n",
    "                idf = np.log(T / df[word])\n",
    "                BOE[cont_doc, dict_emotions[word]] = tf * idf\n",
    "        cont_doc += 1\n",
    "    \n",
    "    return BOE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b482aff8-ff62-4f45-87ed-bdd3bd68e937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[291 127]\n",
      " [ 97  72]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7500    0.6962    0.7221       418\n",
      "           1     0.3618    0.4260    0.3913       169\n",
      "\n",
      "    accuracy                         0.6184       587\n",
      "   macro avg     0.5559    0.5611    0.5567       587\n",
      "weighted avg     0.6382    0.6184    0.6269       587\n",
      "\n"
     ]
    }
   ],
   "source": [
    "BOE_tfidf_train = norma_l2(BoE_tfidf(emot_mask_train,reversed_dict))\n",
    "BOE_tfidf_val = norma_l2(BoE_tfidf(emot_mask_val,reversed_dict))\n",
    "\n",
    "grid.fit(BOE_tfidf_train, target_train)\n",
    "y_pred = grid.predict(BOE_tfidf_val)\n",
    "\n",
    "p, r, f, _= precision_recall_fscore_support(target_val, y_pred, average='macro', pos_label=1)\n",
    "\n",
    "print(confusion_matrix(target_val,y_pred))\n",
    "print(metrics.classification_report(target_val,y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea132945-d19c-49ab-840b-0191b5853da5",
   "metadata": {},
   "source": [
    "Comparación de la Bolsa de Emociones con diferentes esquemas de pesado, para cada caso se normalizo utilizando la norma l2. \n",
    "\n",
    "| Pesado              | Accuracy | Macro F1 | F1-score(0) | F1-score(1) |\n",
    "|--------------------|----------|----------|------------|------------|\n",
    "| **Binario**  | 0.6320   | 0.5700   | 0.7333     | 0.4066    |\n",
    "| **Frecuencia**  | 0.6235   | 0.5607   | 0.7268     | 0.3945     |\n",
    "| **TF-IDF**   | 0.6184   | 0.5567   | 0.7221     | 0.3913    |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae3391f-c2ac-492a-9331-f052c8790da1",
   "metadata": {},
   "source": [
    "## Recurso Línguistico de Emociones Mexicano"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fcc50a9-a623-4a0a-b094-ef647e928db3",
   "metadata": {},
   "source": [
    "1. Utilice el recurso léxico llamado \"Spanish Emotion Lexicon (SEL)\" del Dr. Grigori Sidorov,\n",
    "profesor del Centro de Investigación en Computación (CIC) del Instituto Politécnico Nacional, para enmascarar cada palabra con su emoción, y después construir la Bolsa de Emociones con algún pesado (e.g., binario, tf, tfidf). Proponga alguna estrategia para incorporar el \"valor\" del \"Probability Factor of Affective use\" en su representación vectorial del documento. Evalúa y escribe una tabla comparativa a modo de resumen con al menos tres pesados: binario, frecuencia, tfidf. Normalize cada pesado según lo crea conveniente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "70612ef4-56c4-47af-b5dd-a8b45fa61c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"C:\\Users\\ericl\\Downloads\\SEL\\SEL.txt\"\n",
    "\n",
    "SEL = {} #{palabra,(PFA, categoria)}\n",
    "\n",
    "with open(path, \"r\", encoding=\"cp1252\") as f:\n",
    "    next(f)\n",
    "    for line in f:\n",
    "        parts = line.strip().split(\"\\t\")  \n",
    "        if len(parts) == 3:\n",
    "            word, PFA, cat = parts\n",
    "            SEL.setdefault(word, []).append((float(PFA), cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "75afba98-2806-4a0a-9572-cc68dae782a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_SEL(text_train, lexico):\n",
    "    emot_mask = []  \n",
    "    for txt in text_train:\n",
    "        doc = nlp(unidecode(txt.lower()))\n",
    "        tokens = [token.lemma_ for token in doc]  \n",
    "        emotions = []\n",
    "        for word in tokens:\n",
    "            if word in lexico:\n",
    "                fil_emotions = [emotion for pfa, emotion in lexico[word] if pfa > 0.4]\n",
    "                if fil_emotions:\n",
    "                    emotion = max(lexico[word], key=lambda x: x[0])[1]\n",
    "                    emotions.append(emotion)\n",
    "            else:\n",
    "                emotions.append(word)  \n",
    "                \n",
    "        emot_mask.append(Text(emotions))  \n",
    "        \n",
    "    return emot_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c382c4da-2328-4577-b8e1-f2b5380fa2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotSEL_mask_train = mask_SEL(text_train,SEL)\n",
    "emotSEL_mask_val = mask_SEL(text_val,SEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1cfae85d-441f-4513-acc6-7960af552015",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_emotions = {\"Alegría\" : 0,\"Enojo\" : 1,\"Miedo\" : 2,\"Repulsión\" : 3,\"Sorpresa\" : 4,\"Tristeza\" : 5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0056aa1e-ac11-4a82-a76f-686a96c999a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[111 307]\n",
      " [ 39 130]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7400    0.2656    0.3908       418\n",
      "           1     0.2975    0.7692    0.4290       169\n",
      "\n",
      "    accuracy                         0.4106       587\n",
      "   macro avg     0.5187    0.5174    0.4099       587\n",
      "weighted avg     0.6126    0.4106    0.4018       587\n",
      "\n"
     ]
    }
   ],
   "source": [
    "BOE_SEL_bin_train = norma_l2(BoE(emotSEL_mask_train,dict_emotions))\n",
    "BOE_SEL_bin_val = norma_l2(BoE(emotSEL_mask_val,dict_emotions))\n",
    "\n",
    "grid.fit(BOE_SEL_bin_train, target_train)\n",
    "y_pred = grid.predict(BOE_SEL_bin_val)\n",
    "\n",
    "p, r, f, _= precision_recall_fscore_support(target_val, y_pred, average='macro', pos_label=1)\n",
    "\n",
    "print(confusion_matrix(target_val,y_pred))\n",
    "print(metrics.classification_report(target_val,y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "fb69d2d5-b080-43c4-85ba-39427b9a1f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[111 307]\n",
      " [ 39 130]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7400    0.2656    0.3908       418\n",
      "           1     0.2975    0.7692    0.4290       169\n",
      "\n",
      "    accuracy                         0.4106       587\n",
      "   macro avg     0.5187    0.5174    0.4099       587\n",
      "weighted avg     0.6126    0.4106    0.4018       587\n",
      "\n"
     ]
    }
   ],
   "source": [
    "BOE_SEL_frec_train = norma_l2(BoE_frec(emotSEL_mask_train,dict_emotions))\n",
    "BOE_SEL_frec_val = norma_l2(BoE_frec(emotSEL_mask_val,dict_emotions))\n",
    "\n",
    "grid.fit(BOE_SEL_frec_train, target_train)\n",
    "y_pred = grid.predict(BOE_SEL_frec_val)\n",
    "\n",
    "p, r, f, _= precision_recall_fscore_support(target_val, y_pred, average='macro', pos_label=1)\n",
    "\n",
    "print(confusion_matrix(target_val,y_pred))\n",
    "print(metrics.classification_report(target_val,y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4be67998-d05e-491d-959a-34d01f4ae4e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[111 307]\n",
      " [ 40 129]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7351    0.2656    0.3902       418\n",
      "           1     0.2959    0.7633    0.4264       169\n",
      "\n",
      "    accuracy                         0.4089       587\n",
      "   macro avg     0.5155    0.5144    0.4083       587\n",
      "weighted avg     0.6086    0.4089    0.4006       587\n",
      "\n"
     ]
    }
   ],
   "source": [
    "BOE_SEL_tfidf_train = norma_l2(BoE_tfidf(emotSEL_mask_train,dict_emotions))\n",
    "BOE_SEL_tfidf_val = norma_l2(BoE_tfidf(emotSEL_mask_val,dict_emotions))\n",
    "\n",
    "grid.fit(BOE_SEL_tfidf_train, target_train)\n",
    "y_pred = grid.predict(BOE_SEL_tfidf_val)\n",
    "\n",
    "p, r, f, _= precision_recall_fscore_support(target_val, y_pred, average='macro', pos_label=1)\n",
    "\n",
    "print(confusion_matrix(target_val,y_pred))\n",
    "print(metrics.classification_report(target_val,y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a669338d-cd69-4c57-8fd8-8b4529cad53a",
   "metadata": {},
   "source": [
    "Para cada caso se utilizo normalizado ya que mejoró los resultados. \n",
    "\n",
    "| Pesado          | Accuracy | Macro F1 | F1-score(0) | F1-score(1) |\n",
    "|-----------------|----------|----------|-------------|-------------|\n",
    "| **Binario**     | 0.4106   | 0.4099   | 0.3908      | 0.4290      |\n",
    "| **Frecuencia**  | 0.4106   | 0.4099   | 0.3908      | 0.4290      |\n",
    "| **TF-IDF**      | 0.4089    | 0.4083   | 0.3902      | 0.4264      |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08af843f-38d2-4578-b65f-af32f4220ab6",
   "metadata": {},
   "source": [
    "2. Discuta sobre la estrategía que utilizó para incorporar el \"Probability Factor of Affective use\".\n",
    "\n",
    "Se utilizó el __Probability Factor of Affective (PFA)__ para seleccionar las emociones más relevantes asociadas de cada palabra en los tweets, filtrando aquellas con un PFA superior a 0.4. Este umbral se eligió porque proporciona mejores resultados en precisión. Luego, se asignó la emoción con el PFA más alto a cada palabra, asegurando que solo se seleccionen emociones significativas. Aunque se podría considerar agregar más de una emoción cuando ambas tienen un PFA alto, no se observó una mejora significativa al hacerlo.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6aaa95-44ec-4a1c-b00c-64051fb5f11f",
   "metadata": {},
   "source": [
    "## ¿Podemos mejorar con Bigramas?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b854daeb-a219-4919-8c69-29083fa3c2ae",
   "metadata": {},
   "source": [
    "1. Hacer un experimento dónde concatene una buena BoW según sus experimentos anteriores con otra BoW construida a partir de los 1000 bigramas más frecuentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "baed6765-ed4a-4c4a-b3d2-0d318c7e8537",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigramas = nltk.bigrams(corpus)\n",
    "bigramDist = nltk.FreqDist(bigramas)\n",
    "V_bigram = order_dic_frec(bigramDist)\n",
    "V_bigram = V_bigram[:1000]\n",
    "\n",
    "dictBigram_index = dict()\n",
    "count = 0\n",
    "for weight, word in V_bigram:\n",
    "    dictBigram_index[word] = count\n",
    "    count += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "505ff5d9-d612-4af4-a4f6-84b9a6af4f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BoW_bigram(text, vocabulario, dict_index): \n",
    "    BOW = np.zeros((len(text),len(vocabulario)),dtype = int)\n",
    "     \n",
    "    cont_doc = 0 \n",
    "\n",
    "    for doc in text: \n",
    "        fdist_doc = nltk.FreqDist(nltk.bigrams(doc))\n",
    "\n",
    "        #llenar la bolsa \n",
    "        for word in fdist_doc:\n",
    "            if word in dict_index: \n",
    "                BOW[cont_doc,dict_index[word]] = fdist_doc[word]\n",
    "        cont_doc += 1  \n",
    "    \n",
    "    return BOW "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7d806fe1-b751-415d-ba92-edf1cc0bc57d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[358  60]\n",
      " [ 38 131]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9040    0.8565    0.8796       418\n",
      "           1     0.6859    0.7751    0.7278       169\n",
      "\n",
      "    accuracy                         0.8330       587\n",
      "   macro avg     0.7950    0.8158    0.8037       587\n",
      "weighted avg     0.8412    0.8330    0.8359       587\n",
      "\n"
     ]
    }
   ],
   "source": [
    "BoW_bigrams_train = BoW_bigram(text_train,V_bigram,dictBigram_index)\n",
    "BoW_bigrams_val = BoW_bigram(text_val,V_bigram,dictBigram_index)\n",
    "\n",
    "BoW_concatenada_train = norma_l2(np.concatenate((BoW_frec_train,BoW_bigrams_train), axis = 1))\n",
    "BoW_concatenada_val = norma_l2(np.concatenate((BoW_frec_val,BoW_bigrams_val), axis = 1))\n",
    "\n",
    "grid.fit(BoW_concatenada_train, target_train)\n",
    "y_pred = grid.predict(BoW_concatenada_val)\n",
    "\n",
    "p, r, f, _= precision_recall_fscore_support(target_val, y_pred, average='macro', pos_label=1)\n",
    "\n",
    "print(confusion_matrix(target_val,y_pred))\n",
    "print(metrics.classification_report(target_val,y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7761d976-63bd-4dbd-af7e-6a1fc717fa2b",
   "metadata": {},
   "source": [
    "No mejora, pero si consideramos los 5000 bigramas más fecuentes aumneta a 0.8339 en accurracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c64eaf-6f1d-4ead-b43b-1e13cb03c019",
   "metadata": {},
   "source": [
    "2. Hacer un experimento con las Bolsas de Emociones, Bolsa de Palabras y Bolsa de Bigramas; usted elige las dimensionalidades. Para construir la representación final del documento utilice la concatenación de las representaciones según sus observaciones (e.g., Bolsa de Palabras + Bolsa de Bigramas + Bolsa de Sentimientos de Canadá + Bolsa de Sentimientos de Grigori), y aliméntelas a un SVM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8becd199-d388-494c-b780-392ef521b27c",
   "metadata": {},
   "source": [
    "Consideramos la concatenación de las siguintes bolsas \n",
    "\n",
    "-Bolsa de palabras de dimensión 5000 con pesado de frecuencias.<br>\n",
    "-Bolsa de bigramas de dimensión 1000 con pesado de frecuencias<br>\n",
    "-Bolsa de emociones EmoLex con pesado de frecuencias<br>\n",
    "-Bolsa de emociones SEL con pesado TF-IDF<br>\n",
    "\n",
    "\n",
    "Al final se normalizaron. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "9f7badf5-045c-424d-b5ce-6098c486a0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "BOW_huge_train = norma_l2(np.concatenate((BoW_frec_train,BoW_bigrams_train,BOE_tfidf_train, BOE_SEL_frec_train),axis = 1))\n",
    "BOW_huge_val = norma_l2(np.concatenate((BoW_frec_val,BoW_bigrams_val,BOE_tfidf_val,BOE_SEL_frec_val),axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d573b490-8db4-4ad3-822e-c8c8a71d916d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[355  63]\n",
      " [ 47 122]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8831    0.8493    0.8659       418\n",
      "           1     0.6595    0.7219    0.6893       169\n",
      "\n",
      "    accuracy                         0.8126       587\n",
      "   macro avg     0.7713    0.7856    0.7776       587\n",
      "weighted avg     0.8187    0.8126    0.8150       587\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grid.fit(BOW_huge_train, target_train)\n",
    "y_pred = grid.predict(BOW_huge_val)\n",
    "\n",
    "p, r, f, _= precision_recall_fscore_support(target_val, y_pred, average='macro', pos_label=1)\n",
    "\n",
    "print(confusion_matrix(target_val,y_pred))\n",
    "print(metrics.classification_report(target_val,y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ce6491-cee4-4dbe-9898-377005cf131a",
   "metadata": {},
   "source": [
    "3. Elabore conclusiones sobre toda esta Tarea, incluyendo observaciones, comentarios y posibles mejoras futuras. Discuta el comportamiento de la BoW de usar solo palabras a integrar bigramas, y luego a integrar todo ¿ayudó? o ¿empeoró?. Discuta también brevemente el costo computacional de los experimentos ¿Valió la Pena tener todo?. Sea breve: todo en NO más de dos párrafos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4608a1f-d3d0-426c-86ca-6cc1fe7bbd82",
   "metadata": {},
   "source": [
    "El modelo BoW con esquema de pesado de frecuencias fue el que tuvo un mejor desempeño, el cual mejoró al normalizar por columnas la matriz de término-vocabulario. El agregar bigramas no mejoró mucho el rendimiento, aunque sí hubo una mejora mínima al considerar grandes cantidades de bigramas (alrededor de 10,000).\n",
    "El uso de estrategias de pesado más ingeniosas no mostró resultados de mejora, como en el caso de la TF-IDF. Por otro lado, para las emociones, dado que eran pocas, obtuvimos representaciones más densas de los términos, aunque los resultados fueron inferiores a los obtenidos con estrategias más sencillas como la bolsa de palabras con pesado binario. Aumentar el tamaño del vocabulario mejoró los resultados, pero llegó a un punto donde no se encontraron mejoras significativas. Por lo tanto, no vale la pena considerar toda la información. \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
